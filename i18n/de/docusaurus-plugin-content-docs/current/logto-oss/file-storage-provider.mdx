---
sidebar_position: 6
---

# Dateispeicheranbieter

Standardmäßig verwendet die Logto-Konsole ein Texteingabefeld für statische Dateiadressen wie Avatare. Um eine intuitivere Dateiupload-Erfahrung mit Drag-and-Drop zu ermöglichen, musst du einen Speicheranbieter konfigurieren.

Logto unterstützt mehrere Speicheranbieter, darunter AWS S3 und Azure Storage. Dieses Rezept zeigt dir, wie du einen Speicheranbieter für Logto konfigurierst.

Die Konfiguration wird in der `systems`-Tabelle der Datenbank gespeichert, es wird jedoch empfohlen, die CLI zu verwenden, um den Speicheranbieter zu konfigurieren. Für weitere Informationen, versuche den "help"-Befehl:

```sh
pnpm logto db system --help
```

## Azure Storage

Azure Storage ist eine leistungsstarke und skalierbare Cloud-Speicherlösung, die es dir ermöglicht, deine Daten in der Cloud zu speichern und zu verwalten. Das folgende Rezept zeigt dir, wie du Azure Storage als Speicheranbieter für Logto konfigurierst.

### Voraussetzungen

- [Azure Storage-Konto](https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview)

### Konfiguration mit CLI

Beispielverwendung:

```
pnpm logto db system set storageProvider '{"provider":"AzureStorage","connectionString":"DefaultEndpointsProtocol=https;AccountName=logto;AccountKey=oRhfTBHOHiBxxxxxxxxxxxxxxxxZ0se6XROftl/Xrow==;EndpointSuffix=core.windows.net","container":"logto"}'
```

#### `connectionString`

Um auf Azure Storage zuzugreifen, musst du eine Verbindungszeichenfolge verwenden, die eine Zeichenfolge ist, die die notwendigen Informationen für die Herstellung einer Verbindung zu deinem Speicherkonto enthält.

Um die Verbindungszeichenfolge zu erhalten, folge der offiziellen [Azure Storage-Verbindungszeichenfolgendokumentation](https://docs.microsoft.com/en-us/azure/storage/common/storage-configure-connection-string).

#### `container`

Der Container ist eine Speicherressource, die Blobs speichert. Du kannst den Container verwenden, um deine Blobs zu organisieren und den Zugriff auf deine Daten zu steuern.

Um einen Container zu erstellen, folge der offiziellen [Azure Storage-Containerdokumentation](https://docs.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction#containers).

#### `publicUrl`

Optional.

Die öffentliche URL ist die URL, die verwendet werden kann, um auf die Speicherressource öffentlich zuzugreifen. Wenn du kein CDN verwendest, kannst du es leer lassen, um die standardmäßige "Primäre Endpunkt"-URL von Azure Storage als öffentliche URL zu verwenden. Logto wird diesen Wert aus der "connectionString" mit Hilfe des Azure SDK erhalten. Um mehr über den primären Endpunkt deines Speicherkontos zu erfahren, folge der offiziellen [Azure Storage primäre Endpunktdokumentation](https://docs.microsoft.com/en-us/azure/storage/common/storage-account-overview#primary-endpoints).

## S3 Storage

S3 Storage ist ein Cloud-Speicherdienst, der Objektspeicherung über eine Webdienstschnittstelle bietet. Das folgende Rezept zeigt dir, wie du S3 Storage als Speicheranbieter für Logto konfigurierst.

### Voraussetzungen

- [S3 Storage-Konto](https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-buckets.html) oder ein anderer S3-kompatibler Speicherdienst, wie [MinIO](https://min.io/)

### Konfiguration mit CLI

Beispielverwendung:

```
pnpm logto db system set storageProvider '{"provider":"S3Storage","accessKeyId":"my-access-key-id","accessSecretKey": "my-secret-access-key","bucket":"logto","endpoint":"https://s3.us-east-2.amazonaws.com"}'
```

#### `accessKeyId`

Die Zugangs-Schlüssel-ID ist ein Identifikator für dein AWS-Konto. Um deine Zugangs-Schlüssel-ID für dein AWS-Konto zu finden, folge der offiziellen [AWS Zugangs-Schlüssel-ID-Dokumentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey).

#### `accessSecretKey`

Der geheime Zugangsschlüssel wird zusammen mit der Zugangs-Schlüssel-ID verwendet, um programmatische Anfragen zu signieren. Um deinen geheimen Zugangsschlüssel für dein AWS-Konto zu finden, folge der offiziellen [AWS geheime Zugangsschlüssel-Dokumentation](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_access-keys.html#Using_CreateAccessKey).

#### `bucket`

Der Bucket ist ein Container für Objekte, die in Amazon S3 gespeichert sind. Um einen Bucket zu erstellen, folge der offiziellen [AWS S3 Bucket-Dokumentation](https://docs.aws.amazon.com/AmazonS3/latest/userguide/creating-buckets.html).

#### `region`

Optional.

Die Region ist die geografische Region, in der sich der AWS S3-Bucket befindet. Wenn `endpoint` ein standardmäßiger AWS S3-Endpunkt ist, kann er aus `endpoint` analysiert werden. Um deine AWS S3-Region zu finden, folge der offiziellen [AWS S3 Region-Dokumentation](https://docs.aws.amazon.com/general/latest/gr/s3.html).

Wenn du einen S3-kompatiblen Speicherdienst verwendest, kannst du dieses Feld leer lassen.

#### `endpoint`

Optional.

Der Endpunkt ist die URL, die verwendet wird, um auf den AWS S3-Dienst zuzugreifen. Um deinen AWS S3-Endpunkt zu finden, folge der offiziellen [AWS S3 Endpunkt-Dokumentation](https://docs.aws.amazon.com/general/latest/gr/s3.html).

Du kannst dieses Feld leer lassen, um den standardmäßigen Endpunkt für die Region zu verwenden. Wenn du einen S3-kompatiblen Speicherdienst verwendest, kannst du den Endpunkt des Dienstes verwenden.

#### `publicUrl`

Optional.

Die öffentliche URL ist die URL, die verwendet werden kann, um auf die Speicherressource öffentlich zuzugreifen. Wenn du kein CDN verwendest, kannst du es leer lassen, um die standardmäßige URL von S3 Storage zu verwenden.

## Google Cloud Storage

Google Cloud Storage ist ein Cloud-Speicherdienst, der Objektspeicherung über eine Webdienstschnittstelle bietet. Die folgende Anleitung zeigt dir, wie du Google Cloud Storage als Speicheranbieter für Logto konfigurierst.

### Voraussetzungen

- Ein Google Cloud-Projekt
- Ein Bucket, siehe die offizielle Google Cloud-Dokumentation: https://cloud.google.com/storage/docs/creating-buckets.

### Erhalte die Schlüsseldatei

Google Cloud SDKs verwenden häufig eine "Schlüsseldatei". Wenn du mit Google Cloud nicht vertraut bist, könnte dies der herausforderndste Teil sein. So erhältst du sie:

1. Gehe zur Servicekonto-Seite: https://console.cloud.google.com/iam-admin/serviceaccounts
2. Erstelle ein Konto, gib einen Namen ein und fahre dann fort.
3. Wähle im nächsten Schritt die Rolle "Storage Object User". Du kannst sie mit dem Filter finden.
4. Sobald du das Konto erstellt hast, gehe zur Kontodetailseite und wähle den Tab "Schlüssel".
5. Klicke auf "Schlüssel hinzufügen", wähle "Neuen Schlüssel erstellen", wähle im Dialog "json" und lade dann deine json-Datei herunter.

### Füge die Schlüsseldatei zu Logto hinzu

Logto sollte Zugriff auf die Schlüsseldatei haben.

**Ausführung in Node.js**

Kopiere die Datei nach `/path/to/logto/core` und benenne sie in `google-storage-key.json` um.

**Ausführung in einem Docker-Container**

Wenn du Logto in einem Docker-Container ausführst, musst du die Datei in den Container einbinden. Angenommen, du verwendest Docker Compose, füge dies zu deiner Konfiguration hinzu:

```yaml
volumes:
  - ./path/to/google-storage-key.json:/etc/logto/core/google-storage-key.json
```

Denke daran, `/path/to` durch den tatsächlichen Pfad zu ersetzen.

### Konfiguration mit CLI

Beispielverwendung:

```
pnpm logto db system set storageProvider '{"provider":"GoogleStorage","projectId":"psychic-trainer-403801","keyFilename":"google-storage-key.json","bucketName":"logto-test2"}'
```

#### `projectId`

Deine Google Cloud-Projekt-ID.

#### `keyFilename`

Der Name der Schlüsseldatei, wenn du die obigen Schritte befolgst, dann ist es `google-storage-key.json`.

#### `bucketName`

Der Bucket-Name.

#### `publicUrl`

Optional.

Die öffentliche URL ist die URL, die verwendet werden kann, um auf die Speicherressource öffentlich zuzugreifen. Wenn du kein CDN verwendest, kannst du es leer lassen, um die standardmäßige URL von S3 Storage zu verwenden.
